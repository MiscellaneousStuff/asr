{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from jiwer import wer, cer\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "\n",
    "from torchnlp.encoders import LabelEncoder\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-'] 29\n"
     ]
    }
   ],
   "source": [
    "characters = [x for x in \" abcdefghijklmnopqrstuvwxyz-\"]\n",
    "encoder = LabelEncoder(characters)\n",
    "\n",
    "print(encoder.vocab, len(encoder.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=22_050, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "\n",
    "    for (waveform, _, _, utterance) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == \"valid\":\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "\n",
    "        spectrograms.append(spec)\n",
    "        label = encoder.batch_encode(utterance.lower())\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "\n",
    "        cur_target = labels[i][:label_lengths[i]]\n",
    "        if len(cur_target) > 0:\n",
    "            cur_target = \\\n",
    "                \"\".join(encoder.batch_decode(torch.tensor(cur_target)))\n",
    "        else:\n",
    "            cur_target = \"\"\n",
    "        targets.append(cur_target)\n",
    "\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "\n",
    "        cur_decode = decode\n",
    "        if len(cur_decode) > 0:\n",
    "            cur_decode = \\\n",
    "                \"\".join(encoder.batch_decode(torch.tensor(cur_decode)))\n",
    "        else:\n",
    "            cur_decode = \"\"\n",
    "        decodes.append(cur_decode)\n",
    "\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):# experiment):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "    # with experiment.train():\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(spectrograms)  # (batch, time, n_class)\n",
    "        output = F.log_softmax(output, dim=2)\n",
    "        output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "        loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "        loss.backward()\n",
    "\n",
    "        #experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
    "        #experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        iter_meter.step()\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    #with experiment.test():\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            # print(f\"TEST {i}\", decoded_preds, decoded_targets)\n",
    "\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "    #experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
    "    #experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
    "    #experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
    "\n",
    "def main(dataset_path, learning_rate=5e-4, batch_size=20, epochs=10):\n",
    "    hparams = {\n",
    "        \"n_cnn_layers\":  3,\n",
    "        \"n_rnn_layers\":  5,\n",
    "        \"rnn_dim\":       512,\n",
    "        \"n_class\":       len(encoder.vocab),\n",
    "        \"n_feats\":       128,\n",
    "        \"stride\":        2,\n",
    "        \"dropout\":       0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\":    batch_size,\n",
    "        \"epochs\":        epochs\n",
    "    }\n",
    "\n",
    "    # experiment.log_parameters(hparams)\n",
    "    print(\"hparams:\", hparams)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    dataset = torchaudio.datasets.LJSPEECH(dataset_path, download=False)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    train_split = int(len(dataset) * 0.9)\n",
    "    test_split  = len(dataset) - train_split\n",
    "\n",
    "    train_dataset, test_dataset = \\\n",
    "        torch.utils.data.random_split(dataset, [train_split, test_split])\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "    print(\"TRAIN LEN, TEST LEN:\", len(train_loader), len(test_loader))\n",
    "    model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    iter_meter = IterMeter()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter) #, experiment)\n",
    "        test(model, device, test_loader, criterion) # , epoch, iter_meter, experiment)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr  7 21:49:21 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:2B:00.0  On |                  N/A |\n",
      "| 93%   44C    P2    50W / 200W |   3468MiB /  8192MiB |      8%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       905      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A      1457      G   /usr/lib/xorg/Xorg                285MiB |\n",
      "|    0   N/A  N/A      1587      G   /usr/bin/gnome-shell               52MiB |\n",
      "|    0   N/A  N/A      2049      G   ...181418518745761657,131072      110MiB |\n",
      "|    0   N/A  N/A     43702      G   ...RendererForSitePerProcess      118MiB |\n",
      "|    0   N/A  N/A    321114      C   /usr/bin/python3                 2781MiB |\n",
      "|    0   N/A  N/A    327610      G   /usr/lib/firefox/firefox           11MiB |\n",
      "|    0   N/A  N/A    328382      G   /usr/lib/firefox/firefox            2MiB |\n",
      "|    0   N/A  N/A    328512      G   /usr/lib/firefox/firefox            2MiB |\n",
      "|    0   N/A  N/A    328586      G   /usr/lib/firefox/firefox            2MiB |\n",
      "|    0   N/A  N/A    338958      G   ...AAAAAAAAA= --shared-files       47MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams: {'n_cnn_layers': 3, 'n_rnn_layers': 5, 'rnn_dim': 512, 'n_class': 29, 'n_feats': 128, 'stride': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 8, 'epochs': 10}\n",
      "device: cuda\n",
      "TRAIN LEN, TEST LEN: 1474 164\n",
      "SpeechRecognitionModel(\n",
      "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (rescnn_layers): Sequential(\n",
      "    (0): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (birnn_layers): Sequential(\n",
      "    (0): BidirectionalGRU(\n",
      "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): GELU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
      "  )\n",
      ")\n",
      "Num Model Parameters 23705373\n",
      "Train Epoch: 1 [0/11790 (0%)]\tLoss: 8.975731\n",
      "Train Epoch: 1 [800/11790 (7%)]\tLoss: 2.999156\n",
      "Train Epoch: 1 [1600/11790 (14%)]\tLoss: 2.973086\n",
      "Train Epoch: 1 [2400/11790 (20%)]\tLoss: 2.983799\n",
      "Train Epoch: 1 [3200/11790 (27%)]\tLoss: 2.908594\n",
      "Train Epoch: 1 [4000/11790 (34%)]\tLoss: 2.924355\n",
      "Train Epoch: 1 [4800/11790 (41%)]\tLoss: 2.929428\n",
      "Train Epoch: 1 [5600/11790 (47%)]\tLoss: 2.878055\n",
      "Train Epoch: 1 [6400/11790 (54%)]\tLoss: 2.825568\n",
      "Train Epoch: 1 [7200/11790 (61%)]\tLoss: 2.689430\n",
      "Train Epoch: 1 [8000/11790 (68%)]\tLoss: 2.269475\n",
      "Train Epoch: 1 [8800/11790 (75%)]\tLoss: 2.113060\n",
      "Train Epoch: 1 [9600/11790 (81%)]\tLoss: 1.703053\n",
      "Train Epoch: 1 [10400/11790 (88%)]\tLoss: 1.485067\n",
      "Train Epoch: 1 [11200/11790 (95%)]\tLoss: 1.393101\n",
      "\n",
      "evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_321114/3377958945.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\".join(encoder.batch_decode(torch.tensor(cur_target)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Average loss: 1.5383, Average CER: 0.476363 Average WER: 0.9211\n",
      "\n",
      "Train Epoch: 2 [0/11790 (0%)]\tLoss: 1.305465\n",
      "Train Epoch: 2 [800/11790 (7%)]\tLoss: 1.386022\n",
      "Train Epoch: 2 [1600/11790 (14%)]\tLoss: 1.221313\n",
      "Train Epoch: 2 [2400/11790 (20%)]\tLoss: 1.116396\n",
      "Train Epoch: 2 [3200/11790 (27%)]\tLoss: 1.144018\n",
      "Train Epoch: 2 [4000/11790 (34%)]\tLoss: 0.893480\n",
      "Train Epoch: 2 [4800/11790 (41%)]\tLoss: 1.022572\n",
      "Train Epoch: 2 [5600/11790 (47%)]\tLoss: 1.221341\n",
      "Train Epoch: 2 [6400/11790 (54%)]\tLoss: 0.944849\n",
      "Train Epoch: 2 [7200/11790 (61%)]\tLoss: 0.868301\n",
      "Train Epoch: 2 [8000/11790 (68%)]\tLoss: 0.835779\n",
      "Train Epoch: 2 [8800/11790 (75%)]\tLoss: 0.780152\n",
      "Train Epoch: 2 [9600/11790 (81%)]\tLoss: 0.812827\n",
      "Train Epoch: 2 [10400/11790 (88%)]\tLoss: 0.759857\n",
      "Train Epoch: 2 [11200/11790 (95%)]\tLoss: 0.888854\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 1.0441, Average CER: 0.337976 Average WER: 0.8118\n",
      "\n",
      "Train Epoch: 3 [0/11790 (0%)]\tLoss: 0.889504\n",
      "Train Epoch: 3 [800/11790 (7%)]\tLoss: 0.774101\n",
      "Train Epoch: 3 [1600/11790 (14%)]\tLoss: 0.735365\n",
      "Train Epoch: 3 [2400/11790 (20%)]\tLoss: 0.870659\n",
      "Train Epoch: 3 [3200/11790 (27%)]\tLoss: 0.736619\n",
      "Train Epoch: 3 [4000/11790 (34%)]\tLoss: 0.761884\n",
      "Train Epoch: 3 [4800/11790 (41%)]\tLoss: 0.715086\n",
      "Train Epoch: 3 [5600/11790 (47%)]\tLoss: 0.575614\n",
      "Train Epoch: 3 [6400/11790 (54%)]\tLoss: 0.624773\n",
      "Train Epoch: 3 [7200/11790 (61%)]\tLoss: 0.685078\n",
      "Train Epoch: 3 [8000/11790 (68%)]\tLoss: 0.755557\n",
      "Train Epoch: 3 [8800/11790 (75%)]\tLoss: 0.668866\n",
      "Train Epoch: 3 [9600/11790 (81%)]\tLoss: 0.648281\n",
      "Train Epoch: 3 [10400/11790 (88%)]\tLoss: 0.847939\n",
      "Train Epoch: 3 [11200/11790 (95%)]\tLoss: 0.700563\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.9453, Average CER: 0.321182 Average WER: 0.7682\n",
      "\n",
      "Train Epoch: 4 [0/11790 (0%)]\tLoss: 0.644417\n",
      "Train Epoch: 4 [800/11790 (7%)]\tLoss: 0.671733\n",
      "Train Epoch: 4 [1600/11790 (14%)]\tLoss: 0.590571\n",
      "Train Epoch: 4 [2400/11790 (20%)]\tLoss: 0.596390\n",
      "Train Epoch: 4 [3200/11790 (27%)]\tLoss: 0.687683\n",
      "Train Epoch: 4 [4000/11790 (34%)]\tLoss: 0.504828\n",
      "Train Epoch: 4 [4800/11790 (41%)]\tLoss: 0.541019\n",
      "Train Epoch: 4 [5600/11790 (47%)]\tLoss: 0.494995\n",
      "Train Epoch: 4 [6400/11790 (54%)]\tLoss: 0.551426\n",
      "Train Epoch: 4 [7200/11790 (61%)]\tLoss: 0.454946\n",
      "Train Epoch: 4 [8000/11790 (68%)]\tLoss: 0.510602\n",
      "Train Epoch: 4 [8800/11790 (75%)]\tLoss: 0.584452\n",
      "Train Epoch: 4 [9600/11790 (81%)]\tLoss: 0.524658\n",
      "Train Epoch: 4 [10400/11790 (88%)]\tLoss: 0.463016\n",
      "Train Epoch: 4 [11200/11790 (95%)]\tLoss: 0.495439\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.7950, Average CER: 0.268733 Average WER: 0.7021\n",
      "\n",
      "Train Epoch: 5 [0/11790 (0%)]\tLoss: 0.452544\n",
      "Train Epoch: 5 [800/11790 (7%)]\tLoss: 0.462943\n",
      "Train Epoch: 5 [1600/11790 (14%)]\tLoss: 0.477168\n",
      "Train Epoch: 5 [2400/11790 (20%)]\tLoss: 0.508172\n",
      "Train Epoch: 5 [3200/11790 (27%)]\tLoss: 0.443440\n",
      "Train Epoch: 5 [4000/11790 (34%)]\tLoss: 0.486188\n",
      "Train Epoch: 5 [4800/11790 (41%)]\tLoss: 0.570640\n",
      "Train Epoch: 5 [5600/11790 (47%)]\tLoss: 0.360623\n",
      "Train Epoch: 5 [6400/11790 (54%)]\tLoss: 0.468284\n",
      "Train Epoch: 5 [7200/11790 (61%)]\tLoss: 0.392278\n",
      "Train Epoch: 5 [8000/11790 (68%)]\tLoss: 0.500651\n",
      "Train Epoch: 5 [8800/11790 (75%)]\tLoss: 0.404299\n",
      "Train Epoch: 5 [9600/11790 (81%)]\tLoss: 0.396169\n",
      "Train Epoch: 5 [10400/11790 (88%)]\tLoss: 0.474293\n",
      "Train Epoch: 5 [11200/11790 (95%)]\tLoss: 0.370573\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.7157, Average CER: 0.236092 Average WER: 0.6391\n",
      "\n",
      "Train Epoch: 6 [0/11790 (0%)]\tLoss: 0.341232\n",
      "Train Epoch: 6 [800/11790 (7%)]\tLoss: 0.316176\n",
      "Train Epoch: 6 [1600/11790 (14%)]\tLoss: 0.363103\n",
      "Train Epoch: 6 [2400/11790 (20%)]\tLoss: 0.389576\n",
      "Train Epoch: 6 [3200/11790 (27%)]\tLoss: 0.275832\n",
      "Train Epoch: 6 [4000/11790 (34%)]\tLoss: 0.298860\n",
      "Train Epoch: 6 [4800/11790 (41%)]\tLoss: 0.371091\n",
      "Train Epoch: 6 [5600/11790 (47%)]\tLoss: 0.319074\n",
      "Train Epoch: 6 [6400/11790 (54%)]\tLoss: 0.372048\n",
      "Train Epoch: 6 [7200/11790 (61%)]\tLoss: 0.285931\n",
      "Train Epoch: 6 [8000/11790 (68%)]\tLoss: 0.336661\n",
      "Train Epoch: 6 [8800/11790 (75%)]\tLoss: 0.362204\n",
      "Train Epoch: 6 [9600/11790 (81%)]\tLoss: 0.464674\n",
      "Train Epoch: 6 [10400/11790 (88%)]\tLoss: 0.299572\n",
      "Train Epoch: 6 [11200/11790 (95%)]\tLoss: 0.247310\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.6830, Average CER: 0.220809 Average WER: 0.6111\n",
      "\n",
      "Train Epoch: 7 [0/11790 (0%)]\tLoss: 0.445066\n",
      "Train Epoch: 7 [800/11790 (7%)]\tLoss: 0.287890\n",
      "Train Epoch: 7 [1600/11790 (14%)]\tLoss: 0.332066\n",
      "Train Epoch: 7 [2400/11790 (20%)]\tLoss: 0.303987\n",
      "Train Epoch: 7 [3200/11790 (27%)]\tLoss: 0.368060\n",
      "Train Epoch: 7 [4000/11790 (34%)]\tLoss: 0.302828\n",
      "Train Epoch: 7 [4800/11790 (41%)]\tLoss: 0.334168\n",
      "Train Epoch: 7 [5600/11790 (47%)]\tLoss: 0.354752\n",
      "Train Epoch: 7 [6400/11790 (54%)]\tLoss: 0.367881\n",
      "Train Epoch: 7 [7200/11790 (61%)]\tLoss: 0.238703\n",
      "Train Epoch: 7 [8000/11790 (68%)]\tLoss: 0.309949\n",
      "Train Epoch: 7 [8800/11790 (75%)]\tLoss: 0.157781\n",
      "Train Epoch: 7 [9600/11790 (81%)]\tLoss: 0.288163\n",
      "Train Epoch: 7 [10400/11790 (88%)]\tLoss: 0.258936\n",
      "Train Epoch: 7 [11200/11790 (95%)]\tLoss: 0.290509\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.7029, Average CER: 0.219717 Average WER: 0.5991\n",
      "\n",
      "Train Epoch: 8 [0/11790 (0%)]\tLoss: 0.368945\n",
      "Train Epoch: 8 [800/11790 (7%)]\tLoss: 0.372122\n",
      "Train Epoch: 8 [1600/11790 (14%)]\tLoss: 0.235484\n",
      "Train Epoch: 8 [2400/11790 (20%)]\tLoss: 0.217382\n",
      "Train Epoch: 8 [3200/11790 (27%)]\tLoss: 0.201647\n",
      "Train Epoch: 8 [4000/11790 (34%)]\tLoss: 0.312955\n",
      "Train Epoch: 8 [4800/11790 (41%)]\tLoss: 0.257280\n",
      "Train Epoch: 8 [5600/11790 (47%)]\tLoss: 0.221916\n",
      "Train Epoch: 8 [6400/11790 (54%)]\tLoss: 0.264806\n",
      "Train Epoch: 8 [7200/11790 (61%)]\tLoss: 0.295501\n",
      "Train Epoch: 8 [8000/11790 (68%)]\tLoss: 0.186299\n",
      "Train Epoch: 8 [8800/11790 (75%)]\tLoss: 0.276200\n",
      "Train Epoch: 8 [9600/11790 (81%)]\tLoss: 0.290337\n",
      "Train Epoch: 8 [10400/11790 (88%)]\tLoss: 0.188492\n",
      "Train Epoch: 8 [11200/11790 (95%)]\tLoss: 0.180191\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.7561, Average CER: 0.220212 Average WER: 0.6005\n",
      "\n",
      "Train Epoch: 9 [0/11790 (0%)]\tLoss: 0.213337\n",
      "Train Epoch: 9 [800/11790 (7%)]\tLoss: 0.332826\n",
      "Train Epoch: 9 [1600/11790 (14%)]\tLoss: 0.141428\n",
      "Train Epoch: 9 [2400/11790 (20%)]\tLoss: 0.277296\n",
      "Train Epoch: 9 [3200/11790 (27%)]\tLoss: 0.278588\n",
      "Train Epoch: 9 [4000/11790 (34%)]\tLoss: 0.301970\n",
      "Train Epoch: 9 [4800/11790 (41%)]\tLoss: 0.208034\n",
      "Train Epoch: 9 [5600/11790 (47%)]\tLoss: 0.153010\n",
      "Train Epoch: 9 [6400/11790 (54%)]\tLoss: 0.271532\n",
      "Train Epoch: 9 [7200/11790 (61%)]\tLoss: 0.274509\n",
      "Train Epoch: 9 [8000/11790 (68%)]\tLoss: 0.285023\n",
      "Train Epoch: 9 [8800/11790 (75%)]\tLoss: 0.152345\n",
      "Train Epoch: 9 [9600/11790 (81%)]\tLoss: 0.244975\n",
      "Train Epoch: 9 [10400/11790 (88%)]\tLoss: 0.123750\n",
      "Train Epoch: 9 [11200/11790 (95%)]\tLoss: 0.214408\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.7221, Average CER: 0.207023 Average WER: 0.5742\n",
      "\n",
      "Train Epoch: 10 [0/11790 (0%)]\tLoss: 0.186657\n",
      "Train Epoch: 10 [800/11790 (7%)]\tLoss: 0.241875\n",
      "Train Epoch: 10 [1600/11790 (14%)]\tLoss: 0.155071\n",
      "Train Epoch: 10 [2400/11790 (20%)]\tLoss: 0.168972\n",
      "Train Epoch: 10 [3200/11790 (27%)]\tLoss: 0.304375\n",
      "Train Epoch: 10 [4000/11790 (34%)]\tLoss: 0.222887\n",
      "Train Epoch: 10 [4800/11790 (41%)]\tLoss: 0.205389\n",
      "Train Epoch: 10 [5600/11790 (47%)]\tLoss: 0.171832\n",
      "Train Epoch: 10 [6400/11790 (54%)]\tLoss: 0.209288\n",
      "Train Epoch: 10 [7200/11790 (61%)]\tLoss: 0.213241\n",
      "Train Epoch: 10 [8000/11790 (68%)]\tLoss: 0.250877\n",
      "Train Epoch: 10 [8800/11790 (75%)]\tLoss: 0.185427\n",
      "Train Epoch: 10 [9600/11790 (81%)]\tLoss: 0.212742\n",
      "Train Epoch: 10 [10400/11790 (88%)]\tLoss: 0.178889\n",
      "Train Epoch: 10 [11200/11790 (95%)]\tLoss: 0.172449\n",
      "\n",
      "evaluating...\n",
      "Test set: Average loss: 0.6933, Average CER: 0.197939 Average WER: 0.5551\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 8\n",
    "epochs = 10 # 10\n",
    "dataset_path = \"/home/joe/datasets/ljspeech/\"\n",
    "main(dataset_path, learning_rate, batch_size, epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
