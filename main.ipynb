{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "\n",
    "from jiwer import wer, cer\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchaudio\n",
    "\n",
    "from torchnlp.encoders import LabelEncoder\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<unk>', ' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-'] 29\n"
     ]
    }
   ],
   "source": [
    "characters = [x for x in \" abcdefghijklmnopqrstuvwxyz-\"]\n",
    "encoder = LabelEncoder(characters)\n",
    "\n",
    "print(encoder.vocab, len(encoder.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joe/.local/lib/python3.8/site-packages/torchaudio/functional/functional.py:507: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_audio_transforms = nn.Sequential(\n",
    "    torchaudio.transforms.MelSpectrogram(sample_rate=22_050, n_mels=128),\n",
    "    torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
    "    torchaudio.transforms.TimeMasking(time_mask_param=35)\n",
    ")\n",
    "\n",
    "valid_audio_transforms = torchaudio.transforms.MelSpectrogram()\n",
    "\n",
    "def data_processing(data, data_type=\"train\"):\n",
    "    spectrograms = []\n",
    "    labels = []\n",
    "    input_lengths = []\n",
    "    label_lengths = []\n",
    "\n",
    "    for (waveform, _, _, utterance) in data:\n",
    "        if data_type == 'train':\n",
    "            spec = train_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        elif data_type == \"valid\":\n",
    "            spec = valid_audio_transforms(waveform).squeeze(0).transpose(0, 1)\n",
    "        else:\n",
    "            raise Exception('data_type should be train or valid')\n",
    "\n",
    "        spectrograms.append(spec)\n",
    "        label = encoder.batch_encode(utterance.lower())\n",
    "        labels.append(label)\n",
    "        input_lengths.append(spec.shape[0]//2)\n",
    "        label_lengths.append(len(label))\n",
    "\n",
    "    spectrograms = nn.utils.rnn.pad_sequence(spectrograms, batch_first=True).unsqueeze(1).transpose(2, 3)\n",
    "    labels = nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return spectrograms, labels, input_lengths, label_lengths\n",
    "\n",
    "def GreedyDecoder(output, labels, label_lengths, blank_label=28, collapse_repeated=True):\n",
    "    arg_maxes = torch.argmax(output, dim=2)\n",
    "    decodes = []\n",
    "    targets = []\n",
    "    for i, args in enumerate(arg_maxes):\n",
    "        decode = []\n",
    "\n",
    "        cur_target = labels[i][:label_lengths[i]]\n",
    "        if len(cur_target) > 0:\n",
    "            cur_target = \\\n",
    "                \"\".join(encoder.batch_decode(torch.tensor(cur_target)))\n",
    "        else:\n",
    "            cur_target = \"\"\n",
    "        targets.append(cur_target)\n",
    "\n",
    "        for j, index in enumerate(args):\n",
    "            if index != blank_label:\n",
    "                if collapse_repeated and j != 0 and index == args[j -1]:\n",
    "                    continue\n",
    "                decode.append(index.item())\n",
    "\n",
    "        cur_decode = decode\n",
    "        if len(cur_decode) > 0:\n",
    "            cur_decode = \\\n",
    "                \"\".join(encoder.batch_decode(torch.tensor(cur_decode)))\n",
    "        else:\n",
    "            cur_decode = \"\"\n",
    "        decodes.append(cur_decode)\n",
    "\n",
    "    return decodes, targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLayerNorm(nn.Module):\n",
    "    \"\"\"Layer normalization built for cnns input\"\"\"\n",
    "    def __init__(self, n_feats):\n",
    "        super(CNNLayerNorm, self).__init__()\n",
    "        self.layer_norm = nn.LayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x (batch, channel, feature, time)\n",
    "        x = x.transpose(2, 3).contiguous() # (batch, channel, time, feature)\n",
    "        x = self.layer_norm(x)\n",
    "        return x.transpose(2, 3).contiguous() # (batch, channel, feature, time) \n",
    "\n",
    "class ResidualCNN(nn.Module):\n",
    "    \"\"\"Residual CNN inspired by https://arxiv.org/pdf/1603.05027.pdf\n",
    "        except with layer norm instead of batch norm\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel, stride, dropout, n_feats):\n",
    "        super(ResidualCNN, self).__init__()\n",
    "\n",
    "        self.cnn1 = nn.Conv2d(in_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.cnn2 = nn.Conv2d(out_channels, out_channels, kernel, stride, padding=kernel//2)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.layer_norm1 = CNNLayerNorm(n_feats)\n",
    "        self.layer_norm2 = CNNLayerNorm(n_feats)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x  # (batch, channel, feature, time)\n",
    "        x = self.layer_norm1(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.cnn1(x)\n",
    "        x = self.layer_norm2(x)\n",
    "        x = F.gelu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += residual\n",
    "        return x # (batch, channel, feature, time)\n",
    "\n",
    "class BidirectionalGRU(nn.Module):\n",
    "    def __init__(self, rnn_dim, hidden_size, dropout, batch_first):\n",
    "        super(BidirectionalGRU, self).__init__()\n",
    "\n",
    "        self.BiGRU = nn.GRU(\n",
    "            input_size=rnn_dim, hidden_size=hidden_size,\n",
    "            num_layers=1, batch_first=batch_first, bidirectional=True)\n",
    "        self.layer_norm = nn.LayerNorm(rnn_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer_norm(x)\n",
    "        x = F.gelu(x)\n",
    "        x, _ = self.BiGRU(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class SpeechRecognitionModel(nn.Module):\n",
    "    def __init__(self, n_cnn_layers, n_rnn_layers, rnn_dim, n_class, n_feats, stride=2, dropout=0.1):\n",
    "        super(SpeechRecognitionModel, self).__init__()\n",
    "        n_feats = n_feats//2\n",
    "        self.cnn = nn.Conv2d(1, 32, 3, stride=stride, padding=3//2)  # cnn for extracting heirachal features\n",
    "\n",
    "        # n residual cnn layers with filter size of 32\n",
    "        self.rescnn_layers = nn.Sequential(*[\n",
    "            ResidualCNN(32, 32, kernel=3, stride=1, dropout=dropout, n_feats=n_feats) \n",
    "            for _ in range(n_cnn_layers)\n",
    "        ])\n",
    "        self.fully_connected = nn.Linear(n_feats*32, rnn_dim)\n",
    "        self.birnn_layers = nn.Sequential(*[\n",
    "            BidirectionalGRU(rnn_dim=rnn_dim if i==0 else rnn_dim*2,\n",
    "                             hidden_size=rnn_dim, dropout=dropout, batch_first=i==0)\n",
    "            for i in range(n_rnn_layers)\n",
    "        ])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(rnn_dim*2, rnn_dim),  # birnn returns rnn_dim*2\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(rnn_dim, n_class)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cnn(x)\n",
    "        x = self.rescnn_layers(x)\n",
    "        sizes = x.size()\n",
    "        x = x.view(sizes[0], sizes[1] * sizes[2], sizes[3])  # (batch, feature, time)\n",
    "        x = x.transpose(1, 2) # (batch, time, feature)\n",
    "        x = self.fully_connected(x)\n",
    "        x = self.birnn_layers(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train / Test Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.cuda.amp.grad_scaler import GradScaler\n",
    "\n",
    "amp_enabled = True\n",
    "\n",
    "class IterMeter(object):\n",
    "    \"\"\"keeps track of total iterations\"\"\"\n",
    "    def __init__(self):\n",
    "        self.val = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.val += 1\n",
    "\n",
    "    def get(self):\n",
    "        return self.val\n",
    "\n",
    "def train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter):# experiment):\n",
    "    model.train()\n",
    "    data_len = len(train_loader.dataset)\n",
    "\n",
    "    # AMP\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # with experiment.train():\n",
    "    for batch_idx, _data in enumerate(train_loader):\n",
    "        spectrograms, labels, input_lengths, label_lengths = _data \n",
    "        spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "        # optimizer.zero_grad()\n",
    "        \n",
    "        with torch.autocast(\n",
    "            enabled=amp_enabled,\n",
    "            dtype=torch.bfloat16,\n",
    "            device_type=\"cuda\"):\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "\n",
    "        # loss.backward()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        # scaler.step(scheduler)\n",
    "        scaler.update()\n",
    "\n",
    "        #experiment.log_metric('loss', loss.item(), step=iter_meter.get())\n",
    "        #experiment.log_metric('learning_rate', scheduler.get_lr(), step=iter_meter.get())\n",
    "\n",
    "        #optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        iter_meter.step()\n",
    "        if batch_idx % 100 == 0 or batch_idx == data_len:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(spectrograms), data_len,\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader, criterion):\n",
    "    print('\\nevaluating...')\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    test_cer, test_wer = [], []\n",
    "    #with experiment.test():\n",
    "    with torch.no_grad():\n",
    "        for i, _data in enumerate(test_loader):\n",
    "            spectrograms, labels, input_lengths, label_lengths = _data \n",
    "            spectrograms, labels = spectrograms.to(device), labels.to(device)\n",
    "\n",
    "            output = model(spectrograms)  # (batch, time, n_class)\n",
    "            output = F.log_softmax(output, dim=2)\n",
    "            output = output.transpose(0, 1) # (time, batch, n_class)\n",
    "\n",
    "            loss = criterion(output, labels, input_lengths, label_lengths)\n",
    "            test_loss += loss.item() / len(test_loader)\n",
    "\n",
    "            decoded_preds, decoded_targets = GreedyDecoder(output.transpose(0, 1), labels, label_lengths)\n",
    "            # print(f\"TEST {i}\", decoded_preds, decoded_targets)\n",
    "\n",
    "            for j in range(len(decoded_preds)):\n",
    "                test_cer.append(cer(decoded_targets[j], decoded_preds[j]))\n",
    "                test_wer.append(wer(decoded_targets[j], decoded_preds[j]))\n",
    "\n",
    "\n",
    "    avg_cer = sum(test_cer)/len(test_cer)\n",
    "    avg_wer = sum(test_wer)/len(test_wer)\n",
    "    #experiment.log_metric('test_loss', test_loss, step=iter_meter.get())\n",
    "    #experiment.log_metric('cer', avg_cer, step=iter_meter.get())\n",
    "    #experiment.log_metric('wer', avg_wer, step=iter_meter.get())\n",
    "\n",
    "    print('Test set: Average loss: {:.4f}, Average CER: {:4f} Average WER: {:.4f}\\n'.format(test_loss, avg_cer, avg_wer))\n",
    "\n",
    "def main(dataset_path, learning_rate=5e-4, batch_size=20, epochs=10):\n",
    "    hparams = {\n",
    "        \"n_cnn_layers\":  3,\n",
    "        \"n_rnn_layers\":  5,\n",
    "        \"rnn_dim\":       512,\n",
    "        \"n_class\":       len(encoder.vocab),\n",
    "        \"n_feats\":       128,\n",
    "        \"stride\":        2,\n",
    "        \"dropout\":       0.1,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\":    batch_size,\n",
    "        \"epochs\":        epochs\n",
    "    }\n",
    "\n",
    "    # experiment.log_parameters(hparams)\n",
    "    print(\"hparams:\", hparams)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    torch.manual_seed(7)\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print(\"device:\", device)\n",
    "\n",
    "    dataset = torchaudio.datasets.LJSPEECH(dataset_path, download=False)\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "\n",
    "    train_split = int(len(dataset) * 0.9)\n",
    "    test_split  = len(dataset) - train_split\n",
    "\n",
    "    train_dataset, test_dataset = \\\n",
    "        torch.utils.data.random_split(dataset, [train_split, test_split])\n",
    "    train_loader = data.DataLoader(dataset=train_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=True,\n",
    "                                collate_fn=lambda x: data_processing(x, 'train'),\n",
    "                                **kwargs)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset,\n",
    "                                batch_size=hparams['batch_size'],\n",
    "                                shuffle=False,\n",
    "                                collate_fn=lambda x: data_processing(x, 'valid'),\n",
    "                                **kwargs)\n",
    "    print(\"TRAIN LEN, TEST LEN:\", len(train_loader), len(test_loader))\n",
    "    model = SpeechRecognitionModel(\n",
    "        hparams['n_cnn_layers'], hparams['n_rnn_layers'], hparams['rnn_dim'],\n",
    "        hparams['n_class'], hparams['n_feats'], hparams['stride'], hparams['dropout']\n",
    "    ).to(device)\n",
    "\n",
    "    print(model)\n",
    "    print('Num Model Parameters', sum([param.nelement() for param in model.parameters()]))\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), hparams['learning_rate'])\n",
    "    criterion = nn.CTCLoss(blank=28).to(device)\n",
    "    scheduler = optim.lr_scheduler.OneCycleLR(optimizer, max_lr=hparams['learning_rate'], \n",
    "                                            steps_per_epoch=int(len(train_loader)),\n",
    "                                            epochs=hparams['epochs'],\n",
    "                                            anneal_strategy='linear')\n",
    "    \n",
    "    iter_meter = IterMeter()\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter) #, experiment)\n",
    "        test(model, device, test_loader, criterion) # , epoch, iter_meter, experiment)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  8 00:08:25 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  On   | 00000000:2B:00.0  On |                  N/A |\n",
      "|  0%   39C    P5    29W / 200W |    500MiB /  8192MiB |     42%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A       905      G   /usr/lib/xorg/Xorg                 35MiB |\n",
      "|    0   N/A  N/A      1457      G   /usr/lib/xorg/Xorg                185MiB |\n",
      "|    0   N/A  N/A      1587      G   /usr/bin/gnome-shell               56MiB |\n",
      "|    0   N/A  N/A      2049      G   ...181418518745761657,131072      115MiB |\n",
      "|    0   N/A  N/A    352533      G   ...RendererForSitePerProcess       92MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hparams: {'n_cnn_layers': 3, 'n_rnn_layers': 5, 'rnn_dim': 512, 'n_class': 29, 'n_feats': 128, 'stride': 2, 'dropout': 0.1, 'learning_rate': 0.0005, 'batch_size': 32, 'epochs': 3}\n",
      "device: cuda\n",
      "TRAIN LEN, TEST LEN: 369 41\n",
      "SpeechRecognitionModel(\n",
      "  (cnn): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "  (rescnn_layers): Sequential(\n",
      "    (0): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "    (2): ResidualCNN(\n",
      "      (cnn1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (cnn2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (dropout1): Dropout(p=0.1, inplace=False)\n",
      "      (dropout2): Dropout(p=0.1, inplace=False)\n",
      "      (layer_norm1): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layer_norm2): CNNLayerNorm(\n",
      "        (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (fully_connected): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  (birnn_layers): Sequential(\n",
      "    (0): BidirectionalGRU(\n",
      "      (BiGRU): GRU(512, 512, batch_first=True, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (1): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (2): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (3): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (4): BidirectionalGRU(\n",
      "      (BiGRU): GRU(1024, 512, bidirectional=True)\n",
      "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    (1): GELU()\n",
      "    (2): Dropout(p=0.1, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=29, bias=True)\n",
      "  )\n",
      ")\n",
      "Num Model Parameters 23705373\n",
      "Train Epoch: 1 [0/11790 (0%)]\tLoss: 9.068709\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 186.00 MiB (GPU 0; 7.79 GiB total capacity; 5.02 GiB already allocated; 172.56 MiB free; 5.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/joe/projects/asr/main.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000012?line=2'>3</a>\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39m# 10\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000012?line=3'>4</a>\u001b[0m dataset_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/joe/datasets/ljspeech/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000012?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m main(dataset_path, learning_rate, batch_size, epochs)\n",
      "\u001b[1;32m/home/joe/projects/asr/main.ipynb Cell 9'\u001b[0m in \u001b[0;36mmain\u001b[0;34m(dataset_path, learning_rate, batch_size, epochs)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=149'>150</a>\u001b[0m iter_meter \u001b[39m=\u001b[39m IterMeter()\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=150'>151</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=151'>152</a>\u001b[0m     train(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter) \u001b[39m#, experiment)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=152'>153</a>\u001b[0m     test(model, device, test_loader, criterion) \u001b[39m# , epoch, iter_meter, experiment)\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=154'>155</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "\u001b[1;32m/home/joe/projects/asr/main.ipynb Cell 9'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, criterion, optimizer, scheduler, epoch, iter_meter)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=27'>28</a>\u001b[0m \u001b[39m# optimizer.zero_grad()\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=29'>30</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautocast(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=30'>31</a>\u001b[0m     enabled\u001b[39m=\u001b[39mamp_enabled,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=31'>32</a>\u001b[0m     dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mbfloat16,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=32'>33</a>\u001b[0m     device_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=34'>35</a>\u001b[0m     output \u001b[39m=\u001b[39m model(spectrograms)  \u001b[39m# (batch, time, n_class)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=35'>36</a>\u001b[0m     output \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mlog_softmax(output, dim\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000008?line=36'>37</a>\u001b[0m     output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m# (time, batch, n_class)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/joe/projects/asr/main.ipynb Cell 7'\u001b[0m in \u001b[0;36mSpeechRecognitionModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=85'>86</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m) \u001b[39m# (batch, time, feature)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=86'>87</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfully_connected(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=87'>88</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbirnn_layers(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=88'>89</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=89'>90</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/joe/projects/asr/main.ipynb Cell 7'\u001b[0m in \u001b[0;36mBidirectionalGRU.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=50'>51</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=51'>52</a>\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mgelu(x)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=52'>53</a>\u001b[0m x, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mBiGRU(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=53'>54</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/joe/projects/asr/main.ipynb#ch0000006?line=54'>55</a>\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py:942\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=939'>940</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=940'>941</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=941'>942</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mgru(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=942'>943</a>\u001b[0m                      \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=943'>944</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=944'>945</a>\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mgru(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    <a href='file:///home/joe/.local/lib/python3.8/site-packages/torch/nn/modules/rnn.py?line=945'>946</a>\u001b[0m                      \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 186.00 MiB (GPU 0; 7.79 GiB total capacity; 5.02 GiB already allocated; 172.56 MiB free; 5.30 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "learning_rate = 5e-4\n",
    "batch_size = 32\n",
    "epochs = 3 # 10\n",
    "dataset_path = \"/home/joe/datasets/ljspeech/\"\n",
    "model = main(dataset_path, learning_rate, batch_size, epochs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
